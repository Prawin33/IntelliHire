{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca35273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prave\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\Prave\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\Prave\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\Prave\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\Prave\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume information updated successfully in Excel sheet!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prave\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "C:\\Users\\Prave\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import subprocess  \n",
    "import docx\n",
    "import os\n",
    "import nltk\n",
    "from openpyxl import Workbook\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from pyresparser import ResumeParser\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def read_docx(file_path):\n",
    "            doc = docx.Document(file_path)\n",
    "            full_text = []\n",
    "            for para in doc.paragraphs:\n",
    "             full_text.append(para.text)\n",
    "            return \"\\n\".join(full_text)\n",
    "\n",
    "def extract_email_addresses(text):\n",
    "    # Regular expression to match email addresses\n",
    "    email_regex = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\"\n",
    "    email_addresses = re.findall(email_regex, text)\n",
    "    return email_addresses\n",
    "\n",
    "\n",
    "def extract_phone_numbers(text):\n",
    "    # Regular expression to match phone numbers\n",
    "    phone_regex = r\"\\b(?:\\+\\d{1,2}\\s?)?(?:\\(\\d{3}\\)|\\d{3})[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b\"\n",
    "    phone_numbers = re.findall(phone_regex, text)\n",
    "    return phone_numbers\n",
    "\n",
    "def extract_years_of_experience(text):\n",
    "    \n",
    "    '''\n",
    "    Helper function to extract experience from resume text\n",
    "\n",
    "    :param resume_text: Plain resume text\n",
    "    :return: list of experience\n",
    "    '''\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # word tokenization \n",
    "    word_tokens = nltk.word_tokenize(resume_text)\n",
    "\n",
    "    # remove stop words and lemmatize  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words and wordnet_lemmatizer.lemmatize(w) not in stop_words] \n",
    "    sent = nltk.pos_tag(filtered_sentence)\n",
    "\n",
    "    # parse regex\n",
    "    cp = nltk.RegexpParser('P: {<NNP>+}')\n",
    "    cs = cp.parse(sent)\n",
    "    \n",
    "    # for i in cs.subtrees(filter=lambda x: x.label() == 'P'):\n",
    "    #     print(i)\n",
    "    \n",
    "    test = []\n",
    "    \n",
    "    for vp in list(cs.subtrees(filter=lambda x: x.label()=='P')):\n",
    "        test.append(\" \".join([i[0] for i in vp.leaves() if len(vp.leaves()) >= 2]))\n",
    "\n",
    "    # Search the word 'experience' in the chunk and then print out the text after it\n",
    "    x = [x[x.lower().index('experience') + 10:] for i, x in enumerate(test) if x and 'experience' in x.lower()]\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def extract_experience_years(resume_text):\n",
    "   \n",
    "    # Regular expression to match years of experience\n",
    "    experience_regex = r\"(\\d+)\\s*\\s*?(?:\\s*year|yr|years|yrs)\"\n",
    "    matches = re.findall(experience_regex, resume_text, re.IGNORECASE)\n",
    "    \n",
    "    total_years = 0\n",
    "    for match in matches:\n",
    "        total_years += int(match)\n",
    "    \n",
    "    return total_years\n",
    "    \n",
    "def extract_skills(resume_text, skills_list):\n",
    "    extracted_skills = []\n",
    "    for skill in skills_list:\n",
    "        if skill.lower() in resume_text.lower():\n",
    "            extracted_skills.append(skill)\n",
    "    return extracted_skills\n",
    "\n",
    "def extract_tfidf(text):\n",
    "    # Create a TF-IDF vectorizer\n",
    "    lowercase_list = [item.lower() for item in skills_list]\n",
    "    \n",
    "    tfidf_scores =[]\n",
    "\n",
    "    vectorizer = TfidfVectorizer(vocabulary= skills_list, lowercase=True)\n",
    "\n",
    "     # Fit the vectorizer on the documents and transform them into TF-IDF vectors\n",
    "    tfidf_matrix = vectorizer.fit_transform(resume_texts)\n",
    "\n",
    "     # Get feature names (terms)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "     # Convert TF-IDF matrix to DataFrame for better visualization\n",
    "    \n",
    "    df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "        \n",
    "        #sum_tfidf_scores = df_tfidf.sum(axis=0)\n",
    "    \n",
    "    #for row in df_tfidf.values:\n",
    "       # tfidf_scores.append([int(value) for value in row])\n",
    "\n",
    "    #total = sum(tfidf_scores)\n",
    "    #print(\"KP\",df_tfidf)\n",
    "        \n",
    "    return df_tfidf\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "skills_list = ['java', 'python', 'C', 'JAVASCRIPT', 'smartcomms']\n",
    "\n",
    "\n",
    "email =[]\n",
    "phone =[]\n",
    "skills =[]\n",
    "experience=[]\n",
    "educations =[]\n",
    "header= [\"Email\", \"Phone\", \"Skills\", \"Experience\", \"years of Experience\"]\n",
    "expInyears =[]\n",
    "tfidf_list =[]\n",
    "def read_resume_update_excel(resume_path, excel_path):\n",
    "   \"\"\"\n",
    "   Reads text from a resume file and updates specified fields in an existing Excel sheet.\n",
    "\n",
    "   Args:\n",
    "       resume_path (str): Path to the resume text file.\n",
    "       excel_path (str): Path to the existing Excel sheet.\n",
    "\n",
    "   Returns:\n",
    "       None\n",
    "   \"\"\"\n",
    "\n",
    "   \n",
    "\n",
    "# Example usage:\n",
    "#file_path = \"C:/Users/Prave/Downloads/SortResume/resumes/\"\n",
    "#resume_text = read_docx(file_path)\n",
    "path = r\"C:\\Users\\Prave\\Download\\SortResume\\ResumeDB\\\"\n",
    "  \n",
    "# Change the directory \n",
    "os.chdir(path) \n",
    "  \n",
    "# Read text File \n",
    "  \n",
    "  \n",
    "resume_texts = []\n",
    "tfidf_scores=[]\n",
    "  \n",
    "# iterate through all file \n",
    "for file in os.listdir(): \n",
    "    # Check whether file is in text format or not \n",
    "    if file.endswith(\".docx\"): \n",
    "        file_path = f\"{path}\\{file}\"\n",
    "  \n",
    "        # call read text file function \n",
    "        \n",
    "        resume_text = read_docx(file_path)\n",
    "        \n",
    "        resume_texts.append(resume_text.lower())\n",
    "        \n",
    "        email.append(', '.join(extract_email_addresses(resume_text)))\n",
    "        phone.append(', '.join(extract_phone_numbers(resume_text)))\n",
    "        skills.append(', '.join(extract_skills(resume_text, skills_list)))\n",
    "        experience.append(', '.join(extract_years_of_experience(resume_text)))\n",
    "        expInyears.append(extract_experience_years(resume_text))\n",
    "       \n",
    "   \n",
    "    def write_data_to_excel(excel_file, headers, *lists):\n",
    "        \n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        \n",
    "        # Write headers to the first row\n",
    "        for col, header in enumerate(headers, start=1):\n",
    "            ws.cell(row=1, column=col, value=header)\n",
    "            \n",
    "        \n",
    "        \n",
    "         # Iterate over the lists and write items to respective cells\n",
    "        for col, data_list in enumerate(lists, start=1):\n",
    "            for row, item in enumerate(data_list, start=2):\n",
    "                ws.cell(row=row, column=col, value=item)\n",
    "        \n",
    "\n",
    "        # Save the workbook to the specified Excel file\n",
    "        wb.save(excel_file)\n",
    "    \n",
    "    #skills = ', '.join(extract_skills(resume_text, skills_list))\n",
    "    #experience = extract_years_of_experience(resume_text)\n",
    "\n",
    "    #data = [  email, phone, skills, experience]\n",
    "    \n",
    "    \n",
    "    #print (email)\n",
    "    #print (skills)\n",
    "   # print (\"Test\", extract_experience_years(resume_text))\n",
    "    \n",
    "    \n",
    "    excel_file = r\"C:\\Users\\Prave\\Downloads\\SortResume\\resume.xlsx\"\n",
    "       # Save the updated DataFrame back to the Excel sheet\n",
    "    #df.to_excel(r\"C:\\Users\\Prave\\Downloads\\SortResume\\resume.xlsx\", index = False)\n",
    "    write_data_to_excel(excel_file, header, email, phone, skills, experience, expInyears)\n",
    "    #write_data_to_excel(excel_file,data)\n",
    "    df_tfidf = pd.DataFrame(extract_tfidf(resume_texts))\n",
    "    df_tfidf.to_excel(r\"C:\\Users\\Prave\\Downloads\\SortResume\\Tfidf_scores.xlsx\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "       # Extract necessary information from the resume text (customize based on your needs)\n",
    "       #name = extract_name(resume_text)\n",
    "\n",
    "       \n",
    "print(\"Resume information updated successfully in Excel sheet!\")\n",
    "\n",
    "\n",
    "#except FileNotFoundError as e:\n",
    "      # print(f\"Error: File not found: {e.filename}\")\n",
    "#except Exception as e:\n",
    "      # print(f\"An error occurred: {e}\")\n",
    "       \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f33ad2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\prave\\anaconda3\\lib\\site-packages (0.8)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fd1bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "                          Email                   Phone  \\\n",
      "2      praveen.kale33@gmail.com  9059223961, 8499955008   \n",
      "3  Harshitha.krishnan@gmail.com  7248726876, 5758245285   \n",
      "4     Bhindu.Daruvuri@gmail.com  4561683143, 5645464645   \n",
      "\n",
      "                            Skills  \\\n",
      "2      java, python, C, smartcomms   \n",
      "3      java, python, C, smartcomms   \n",
      "4  java, C, JAVASCRIPT, smartcomms   \n",
      "\n",
      "                                          Experience  years of Experience  \\\n",
      "2   Summary Overall Experience,  Ernst,  HCL Expe...                   12   \n",
      "3   Summary Overall Experience,  Ernst,  HCL Expe...                   13   \n",
      "4   Summary Overall Experience,  Ernst,  HCL Expe...                   12   \n",
      "\n",
      "      score  \n",
      "2  0.002000  \n",
      "3  0.002000  \n",
      "4  0.036167  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "resume_details_csv = r\"C:\\Users\\Prave\\Downloads\\SortResume\\resume.xlsx\"  # Path to your CSV file\n",
    "tfidf_scores_csv = r\"C:\\Users\\Prave\\Downloads\\SortResume\\Tfidf_scores.xlsx\"\n",
    "resumes_df = pd.read_excel(resume_details_csv)\n",
    "tfidfScores_df = pd.read_excel(tfidf_scores_csv)\n",
    "#print(resume_df.head())\n",
    "\n",
    "\n",
    "feature_columns = ['java', 'python', 'JAVASCRIPT', 'smartcomms']\n",
    "\n",
    "X = tfidfScores_df.drop('C', axis=1)  # Features\n",
    "y = resumes_df['years of Experience']  # Labels\n",
    "\n",
    "# Split data into train and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(tfidf_scores_csv[feature_columns], resumes_df['years of Experience'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the classifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Rank resumes based on predicted probabilities or scores\n",
    "resumes_df['score'] = classifier.predict_proba(tfidfScores_df[feature_columns])[:, 1]\n",
    "\n",
    "# Select top 10 candidates\n",
    "top_10_resumes = resumes_df.sort_values(by='score', ascending=True).head(3)\n",
    "top_10_resumes.to_excel(r\"C:\\Users\\Prave\\Downloads\\SortResume\\SortedResumes.xlsx\", index=False)\n",
    "print(top_10_resumes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbe67484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docxNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for python-docx from https://files.pythonhosted.org/packages/5f/d8/6948f7ac00edf74bfa52b3c5e3073df20284bec1db466d13e668fe991707/python_docx-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading python_docx-1.1.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\prave\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\prave\\anaconda3\\lib\\site-packages (from python-docx) (4.7.1)\n",
      "Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 0.0/239.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/239.6 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 41.0/239.6 kB 487.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  235.5/239.6 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 239.6/239.6 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
